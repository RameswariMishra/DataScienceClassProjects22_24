{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Unbiased Evaluation using a New Test Set\n",
    "\n",
    "In this part, we are given a new test set (`/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`). We can now take advantage of the entire smart sample that we created in Part I. \n",
    "\n",
    "* Retrain a pipeline using the optimal parameters that the pipeline learned. We don't need to repeat GridSearch here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load smart sample and the best pipeline from Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1, final_model = joblib.load('pipeline3_model_RF.pkl')\n",
    "X2, Y2, anamoly_model = joblib.load('model3_outlier.pkl')\n",
    "dataset_train = joblib.load('preprocessed_data_part1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Retrain a pipeline using the full sampled training data set\n",
    "\n",
    "Use the full sampled training data set to train the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (22586, 21) y_train (22586,)\n",
      "Num of outliers = 1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('RFE',\n",
      "                 RFE(estimator=LogisticRegression(), n_features_to_select=20)),\n",
      "                ('RandomForest',\n",
      "                 RandomForestClassifier(criterion='entropy', min_samples_leaf=2,\n",
      "                                        min_samples_split=6,\n",
      "                                        n_estimators=30))])\n",
      "Score of the best model: 0.9039431889237818\n"
     ]
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E301)\n",
    "# ----------------------------------\n",
    "X_train = np.array(dataset_train.iloc[:,:-1]) # Pull all rows, each column except the last\n",
    "y_train = np.array(dataset_train.went_on_backorder) # Pull just the went_on_backorder column\n",
    "print('X_train', X_train.shape, 'y_train', y_train.shape)\n",
    "\n",
    "anamoly_model.fit(X_train, y_train)\n",
    "outliers_train = anamoly_model.predict(X_train)==-1\n",
    "print(f\"Num of outliers = {np.sum(outliers_train)}\")\n",
    "X_train_inliers = X_train[~outliers_train]\n",
    "y_train_inliers = y_train[~outliers_train]\n",
    "\n",
    "final_model.fit(X_train_inliers, y_train_inliers)\n",
    "\n",
    "print(\"Parameters of the best model are:\",final_model.best_estimator_)\n",
    "print(\"Score of the best model:\", final_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model with the pickle library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code below this comment  \n",
    "# -----------------------------\n",
    "joblib.dump([X_train_inliers, y_train_inliers, final_model], 'final_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the Testing Data and evaluate your model\n",
    "\n",
    " * `/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`\n",
    " \n",
    "* We need to preprocess this test data (**follow** the steps similar to Part I)\n",
    "* **If you have fitted any normalizer/standardizer in Part 2, then we have to transform this test data using the fitted normalizer/standardizer!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sku</th>\n",
       "      <td>3424460</td>\n",
       "      <td>3285353</td>\n",
       "      <td>3489864</td>\n",
       "      <td>3287008</td>\n",
       "      <td>3496133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national_inv</th>\n",
       "      <td>52.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_transit_qty</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_3_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_6_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_9_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_1_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_3_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_6_month</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_9_month</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_bank</th>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potential_issue</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces_past_due</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_bo_qty</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_risk</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oe_constraint</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppap_risk</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_stop</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went_on_backorder</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0        1        2        3        4\n",
       "sku                3424460  3285353  3489864  3287008  3496133\n",
       "national_inv          52.0    551.0     11.0     13.0      4.0\n",
       "lead_time              2.0      8.0     12.0     14.0      2.0\n",
       "in_transit_qty         0.0     80.0      0.0      0.0      0.0\n",
       "forecast_3_month       0.0    490.0      0.0      0.0      0.0\n",
       "forecast_6_month       0.0    950.0      0.0      0.0      1.0\n",
       "forecast_9_month       0.0   1460.0      0.0      0.0      2.0\n",
       "sales_1_month          0.0    224.0      0.0      3.0      0.0\n",
       "sales_3_month          0.0    737.0      0.0      3.0      1.0\n",
       "sales_6_month          1.0   1338.0      1.0      5.0      8.0\n",
       "sales_9_month          1.0   1988.0      2.0     10.0     14.0\n",
       "min_bank               0.0    161.0      0.0      1.0      0.0\n",
       "potential_issue         No       No       No       No       No\n",
       "pieces_past_due        0.0      0.0      0.0      0.0      0.0\n",
       "perf_6_month_avg       0.9     0.97     0.57     0.99     0.91\n",
       "perf_12_month_avg     0.92     0.95     0.68     0.99     0.94\n",
       "local_bo_qty           0.0      0.0      0.0      0.0      0.0\n",
       "deck_risk               No       No       No       No       No\n",
       "oe_constraint           No       No       No       No       No\n",
       "ppap_risk               No       No       No       No       No\n",
       "stop_auto_buy          Yes      Yes      Yes      Yes      Yes\n",
       "rev_stop                No       No       No       No       No\n",
       "went_on_backorder       No       No       No       No       No"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the given test set  (Question #E302)\n",
    "# ----------------------------------\n",
    "\n",
    "# Dataset location\n",
    "DATASET = '/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Load and shuffle\n",
    "dataset = pd.read_csv(DATASET).sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "dataset.head().transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242076, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>national_inv</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>499.751028</td>\n",
       "      <td>29280.390793</td>\n",
       "      <td>-25414.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>12145792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>227351.0</td>\n",
       "      <td>7.923018</td>\n",
       "      <td>7.041410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_transit_qty</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>36.178213</td>\n",
       "      <td>898.673127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>265272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_3_month</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>181.472345</td>\n",
       "      <td>5648.874620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1510592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_6_month</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>348.807304</td>\n",
       "      <td>10081.797119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2157024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_9_month</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>508.296301</td>\n",
       "      <td>14109.723787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>3162260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_1_month</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>51.478195</td>\n",
       "      <td>1544.678350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>349620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_3_month</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>172.139316</td>\n",
       "      <td>5164.243624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1099852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_6_month</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>340.425414</td>\n",
       "      <td>9386.523492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>2103389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_9_month</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>511.775446</td>\n",
       "      <td>13976.702192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>3195211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_bank</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>52.804693</td>\n",
       "      <td>1278.591177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>303713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces_past_due</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>1.824236</td>\n",
       "      <td>178.679263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>79964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>-7.093779</td>\n",
       "      <td>26.900636</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>-6.632445</td>\n",
       "      <td>26.160720</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_bo_qty</th>\n",
       "      <td>242075.0</td>\n",
       "      <td>0.843726</td>\n",
       "      <td>45.606626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6232.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count        mean           std      min   25%    50%  \\\n",
       "national_inv       242075.0  499.751028  29280.390793 -25414.0  4.00  15.00   \n",
       "lead_time          227351.0    7.923018      7.041410      0.0  4.00   8.00   \n",
       "in_transit_qty     242075.0   36.178213    898.673127      0.0  0.00   0.00   \n",
       "forecast_3_month   242075.0  181.472345   5648.874620      0.0  0.00   0.00   \n",
       "forecast_6_month   242075.0  348.807304  10081.797119      0.0  0.00   0.00   \n",
       "forecast_9_month   242075.0  508.296301  14109.723787      0.0  0.00   0.00   \n",
       "sales_1_month      242075.0   51.478195   1544.678350      0.0  0.00   0.00   \n",
       "sales_3_month      242075.0  172.139316   5164.243624      0.0  0.00   1.00   \n",
       "sales_6_month      242075.0  340.425414   9386.523492      0.0  0.00   2.00   \n",
       "sales_9_month      242075.0  511.775446  13976.702192      0.0  0.00   4.00   \n",
       "min_bank           242075.0   52.804693   1278.591177      0.0  0.00   0.00   \n",
       "pieces_past_due    242075.0    1.824236    178.679263      0.0  0.00   0.00   \n",
       "perf_6_month_avg   242075.0   -7.093779     26.900636    -99.0  0.63   0.82   \n",
       "perf_12_month_avg  242075.0   -6.632445     26.160720    -99.0  0.66   0.81   \n",
       "local_bo_qty       242075.0    0.843726     45.606626      0.0  0.00   0.00   \n",
       "\n",
       "                     75%         max  \n",
       "national_inv       81.00  12145792.0  \n",
       "lead_time           9.00        52.0  \n",
       "in_transit_qty      0.00    265272.0  \n",
       "forecast_3_month    4.00   1510592.0  \n",
       "forecast_6_month   12.00   2157024.0  \n",
       "forecast_9_month   20.00   3162260.0  \n",
       "sales_1_month       4.00    349620.0  \n",
       "sales_3_month      14.00   1099852.0  \n",
       "sales_6_month      30.00   2103389.0  \n",
       "sales_9_month      46.00   3195211.0  \n",
       "min_bank            3.00    303713.0  \n",
       "pieces_past_due     0.00     79964.0  \n",
       "perf_6_month_avg    0.96         1.0  \n",
       "perf_12_month_avg   0.95         1.0  \n",
       "local_bo_qty        0.00      6232.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     239387\n",
       "Yes      2688\n",
       "Name: went_on_backorder, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[:,'went_on_backorder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('sku', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv             1\n",
       "lead_time            14725\n",
       "in_transit_qty           1\n",
       "forecast_3_month         1\n",
       "forecast_6_month         1\n",
       "forecast_9_month         1\n",
       "sales_1_month            1\n",
       "sales_3_month            1\n",
       "sales_6_month            1\n",
       "sales_9_month            1\n",
       "min_bank                 1\n",
       "potential_issue          1\n",
       "pieces_past_due          1\n",
       "perf_6_month_avg         1\n",
       "perf_12_month_avg        1\n",
       "local_bo_qty             1\n",
       "deck_risk                1\n",
       "oe_constraint            1\n",
       "ppap_risk                1\n",
       "stop_auto_buy            1\n",
       "rev_stop                 1\n",
       "went_on_backorder        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']\n",
      "potential_issue: ['No' 'Yes' nan]\n",
      "deck_risk: ['No' 'Yes' nan]\n",
      "oe_constraint ['No' 'Yes' nan]\n",
      "ppap_risk ['No' 'Yes' nan]\n",
      "stop_auto_buy ['Yes' 'No' nan]\n",
      "rev_stop ['No' 'Yes' nan]\n",
      "went_on_backorder ['No' 'Yes' nan]\n"
     ]
    }
   ],
   "source": [
    "yes_no_columns = list(filter(lambda i: dataset[i].dtype!=np.float64, dataset.columns))\n",
    "print(yes_no_columns)\n",
    "\n",
    "# Add code below this comment  (Question #E102)\n",
    "# ----------------------------------\n",
    "print(\"potential_issue:\", dataset.potential_issue.unique())\n",
    "print(\"deck_risk:\", dataset.deck_risk.unique())\n",
    "print(\"oe_constraint\", dataset.oe_constraint.unique())\n",
    "print(\"ppap_risk\", dataset.ppap_risk.unique())\n",
    "print(\"stop_auto_buy\", dataset.stop_auto_buy.unique())\n",
    "print(\"rev_stop\", dataset.rev_stop.unique())\n",
    "print('went_on_backorder', dataset['went_on_backorder'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values of potential_issue with No\n",
      "Filling missing values of deck_risk with No\n",
      "Filling missing values of oe_constraint with No\n",
      "Filling missing values of ppap_risk with No\n",
      "Filling missing values of stop_auto_buy with Yes\n",
      "Filling missing values of rev_stop with No\n",
      "Filling missing values of went_on_backorder with No\n"
     ]
    }
   ],
   "source": [
    "for column_name in yes_no_columns:\n",
    "    mode = dataset[column_name].apply(str).mode()[0]\n",
    "    print('Filling missing values of {} with {}'.format(column_name, mode))\n",
    "    dataset[column_name].fillna(mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv             1\n",
       "lead_time            14725\n",
       "in_transit_qty           1\n",
       "forecast_3_month         1\n",
       "forecast_6_month         1\n",
       "forecast_9_month         1\n",
       "sales_1_month            1\n",
       "sales_3_month            1\n",
       "sales_6_month            1\n",
       "sales_9_month            1\n",
       "min_bank                 1\n",
       "potential_issue          0\n",
       "pieces_past_due          1\n",
       "perf_6_month_avg         1\n",
       "perf_12_month_avg        1\n",
       "local_bo_qty             1\n",
       "deck_risk                0\n",
       "oe_constraint            0\n",
       "ppap_risk                0\n",
       "stop_auto_buy            0\n",
       "rev_stop                 0\n",
       "went_on_backorder        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    227351\n",
       "True      14725\n",
       "Name: lead_time, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[:,'lead_time'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv         0\n",
       "lead_time            0\n",
       "in_transit_qty       0\n",
       "forecast_3_month     0\n",
       "forecast_6_month     0\n",
       "forecast_9_month     0\n",
       "sales_1_month        0\n",
       "sales_3_month        0\n",
       "sales_6_month        0\n",
       "sales_9_month        0\n",
       "min_bank             0\n",
       "potential_issue      0\n",
       "pieces_past_due      0\n",
       "perf_6_month_avg     0\n",
       "perf_12_month_avg    0\n",
       "local_bo_qty         0\n",
       "deck_risk            0\n",
       "oe_constraint        0\n",
       "ppap_risk            0\n",
       "stop_auto_buy        0\n",
       "rev_stop             0\n",
       "went_on_backorder    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['lead_time'].fillna(dataset['lead_time'].mode()[0], inplace=True)\n",
    "\n",
    "dataset = dataset.dropna()\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = dataset.select_dtypes(include = ['object']).columns\n",
    "for col in cat:\n",
    "    dataset[col].replace({'No': 0, 'Yes': 1}, inplace=True)\n",
    "    dataset[col] = dataset[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential_issue: [0 1]\n",
      "deck_risk: [0 1]\n",
      "oe_constraint [0 1]\n",
      "ppap_risk [0 1]\n",
      "stop_auto_buy [1 0]\n",
      "rev_stop [0 1]\n",
      "went_on_backorder [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"potential_issue:\", dataset.potential_issue.unique())\n",
    "print(\"deck_risk:\", dataset.deck_risk.unique())\n",
    "print(\"oe_constraint\", dataset.oe_constraint.unique())\n",
    "print(\"ppap_risk\", dataset.ppap_risk.unique())\n",
    "print(\"stop_auto_buy\", dataset.stop_auto_buy.unique())\n",
    "print(\"rev_stop\", dataset.rev_stop.unique())\n",
    "print('went_on_backorder', dataset['went_on_backorder'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 242075 entries, 0 to 242075\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   national_inv       242075 non-null  float64\n",
      " 1   lead_time          242075 non-null  float64\n",
      " 2   in_transit_qty     242075 non-null  float64\n",
      " 3   forecast_3_month   242075 non-null  float64\n",
      " 4   forecast_6_month   242075 non-null  float64\n",
      " 5   forecast_9_month   242075 non-null  float64\n",
      " 6   sales_1_month      242075 non-null  float64\n",
      " 7   sales_3_month      242075 non-null  float64\n",
      " 8   sales_6_month      242075 non-null  float64\n",
      " 9   sales_9_month      242075 non-null  float64\n",
      " 10  min_bank           242075 non-null  float64\n",
      " 11  potential_issue    242075 non-null  int64  \n",
      " 12  pieces_past_due    242075 non-null  float64\n",
      " 13  perf_6_month_avg   242075 non-null  float64\n",
      " 14  perf_12_month_avg  242075 non-null  float64\n",
      " 15  local_bo_qty       242075 non-null  float64\n",
      " 16  deck_risk          242075 non-null  int64  \n",
      " 17  oe_constraint      242075 non-null  int64  \n",
      " 18  ppap_risk          242075 non-null  int64  \n",
      " 19  stop_auto_buy      242075 non-null  int64  \n",
      " 20  rev_stop           242075 non-null  int64  \n",
      " 21  went_on_backorder  242075 non-null  int64  \n",
      "dtypes: float64(15), int64(7)\n",
      "memory usage: 42.5 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict and evaluate with the preprocessed test set. It would be interesting to see the performance with and without outliers removal from the test set. We can report confusion matrix, precision, recall, f1-score, accuracy, and other measures (if any). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making X and y split of Testing dataset for final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test (242075, 21) y_test (242075,)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(dataset.iloc[:,:-1]) # Pull all rows, each column except the last\n",
    "y_test = np.array(dataset.went_on_backorder) # Pull just the went_on_backorder column\n",
    "print('X_test', X_test.shape, 'y_test', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inliers, y_train_inliers, final_model = joblib.load('final_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95    239387\n",
      "           1       0.08      0.80      0.15      2688\n",
      "\n",
      "    accuracy                           0.90    242075\n",
      "   macro avg       0.54      0.85      0.55    242075\n",
      "weighted avg       0.99      0.90      0.94    242075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model prediction with outliers\n",
    "predicted_y = final_model.predict(X_test)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215882</td>\n",
       "      <td>23505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>525</td>\n",
       "      <td>2163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0  215882  23505\n",
       "1     525   2163"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outliers = 12104\n"
     ]
    }
   ],
   "source": [
    "#Removing outliers from test dataset\n",
    "anamoly_model.fit(X_test, y_test)\n",
    "outliers_test = anamoly_model.predict(X_test)==-1\n",
    "print(f\"Num of outliers = {np.sum(outliers_test)}\")\n",
    "X_test_inliers = X_test[~outliers_test]\n",
    "y_test_inliers = y_test[~outliers_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95    227414\n",
      "           1       0.08      0.81      0.15      2557\n",
      "\n",
      "    accuracy                           0.90    229971\n",
      "   macro avg       0.54      0.85      0.55    229971\n",
      "weighted avg       0.99      0.90      0.94    229971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model prediction without outliers\n",
    "predicted_y_inliers = final_model.predict(X_test_inliers)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test_inliers, predicted_y_inliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204595</td>\n",
       "      <td>22819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0  204595  22819\n",
       "1     488   2069"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test_inliers, predicted_y_inliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write a summary of your processing and an analysis of the model performance  \n",
    "# (Question #E304)\n",
    "# ----------------------------------\n",
    "1. Loaded the anamoly model and final model ie. the 3rd pipeline model generated from 2nd file and training dataset from 1st file.\n",
    "2. Did the X and y split of the whole dataset and did removed the outliers by using anamoly detection model.\n",
    "3. Trained the final model with inlier training dataset.\n",
    "4. Loaded the test dataset and did all the preprocessing steps as in file 1, then did split it into Test X and Test y .\n",
    "5. Predicted the performance using the test dataset.\n",
    "6. Found the outliers using the same anamoly method and did the prediction using inlier test data aswell.\n",
    "\n",
    "Model Performance :\n",
    "\n",
    "Did not find much difference in model predictions with and without outliers.\n",
    "\n",
    "The Classification Report for test data:\n",
    "\n",
    "                 precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.90      0.95    227414\n",
    "           1       0.08      0.81      0.15      2557\n",
    "\n",
    "    accuracy                           0.90    229971\n",
    "   macro avg       0.54      0.85      0.55    229971\n",
    "weighted avg       0.99      0.90      0.94    229971\n",
    "\n",
    "\n",
    "Precision:\n",
    "\n",
    "For class 0 (non-backorder): The precision is 1.00, ie. out of all instances predicted as non-backorders, 100% of them were correct, the model predicts that an item is not on backorder, it is accurate 100% of the time, which was 97% for the training data in file2. \n",
    "For class 1 (backorder): The precision is 0.08, ie. out of all instances predicted as backorders, less than 1% of them were correct. So, when the model predicts that an item is on backorder, it is accurate less than 1% of the times, Which was 95% for the training dataset in file2.\n",
    "\n",
    "Recall:\n",
    "\n",
    "For class 0 (non-backorder): The recall is 0.90, ie. the model successfully identified 90% of the actual instances that were non-backorders, which was 95% for the training dataset in file2.  \n",
    "For class 1 (backorder): The recall is 0.81, indicating that the model detected 81% of the actual instances that were backorders, which was 97% in file2. \n",
    "\n",
    "F1-Score:\n",
    "\n",
    "The F1-score is the harmonic mean of precision and recall. In this case, the F1-score is 0.95 for class 0 and 0.15 for class 1, which is good for non-backorder products but not so good for back-order products.\n",
    "\n",
    "\n",
    "The Confusion Matrix for test data:\n",
    "\n",
    "      0\t     1\n",
    "0\t204595\t22819\n",
    "1\t488\t    2069\n",
    "\n",
    "\n",
    "Confusion Matrix :\n",
    "\n",
    "True Negatives (TN): 204595 instances were correctly predicted as non-backorders (class 0).\n",
    "\n",
    "False Positives (FP): 22819 instances were incorrectly predicted as backorders (class 1) when they were actually non-backorders.\n",
    "\n",
    "False Negatives (FN): 488 instances were incorrectly predicted as non-backorders when they were actually backorders.\n",
    "\n",
    "True Positives (TP): 2069 instances were correctly predicted as backorders.\n",
    "\n",
    "There is a huge class imbalance, we can easily find that from the prediction, so the smaller class ie. having backorders can not be predicted accurately. For this we can make the model more robust by taking correct percentages of different classes, which can represent the real world of data while sampling to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect\n",
    "\n",
    "Imagine you are data scientist that has been tasked with developing a system to save your \n",
    "company money by predicting and preventing back orders of parts in the supply chain.\n",
    "\n",
    "Write a **brief summary** for \"management\" that details your findings, \n",
    "your level of certainty and trust in the models, \n",
    "and recommendations for operationalizing these models for the business."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your answer here:  \n",
    "# (Question #E305)\n",
    "# ----------------------------------\n",
    "When there is a discrepancy between customer demand and available inventory, backorders may happen. Management may learn more about consumer preferences, market trends, and seasonal variations through improving demand forecasting techniques. This can aid in precisely forecasting demand and guaranteeing enough stock levels to reduce backorders.\n",
    "\n",
    "For Class 1 ie. back-order has a precision score of 0.08, which is pretty poor. This suggests that there are a lot of false positives, which means that many items are displayed as backordered even when they are truly in stock. So to manage customer demand and reduce the likelihood of backorders, management should think about raising inventory levels.\n",
    "\n",
    "Recall score for back-order class is 0.81, which indicates that a sizable proportion of backordered products are being accurately identified. This also suggests that there may still be situations where incorrect identification of backordered products results in unhappy customers. In order to assure prompt delivery and lower the quantity of backordered goods, management should concentrate on optimizing order fulfillment procedures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
